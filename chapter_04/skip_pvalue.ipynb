{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e14e56a-8aa6-4839-b5ac-78cfab9ce98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NB fits: 100%|███████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 461.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean relative error (means):     0.041\n",
      "Mean relative error (variances): 0.100\n",
      "Fraction KS rejections (α=0.05): 0.00%\n",
      "Frobenius-norm error (corr):     0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import t, ttest_1samp, rankdata, spearmanr\n",
    "\n",
    "# 1) BH on p-values (NumPy)\n",
    "def bh_pvalue(pvals, q=0.05):\n",
    "    M = pvals.size\n",
    "    order = np.argsort(pvals)\n",
    "    thresh = (np.arange(1, M+1) * q / M)\n",
    "    leq = pvals[order] <= thresh\n",
    "    keep = np.zeros(M, bool)\n",
    "    if np.any(leq):\n",
    "        k = np.max(np.where(leq)[0]) + 1\n",
    "        keep[order[:k]] = True\n",
    "    return keep\n",
    "\n",
    "# 2) BH on t-stats (NumPy)\n",
    "def bh_tstat_numpy(t_stats, df, q=0.05):\n",
    "    M = t_stats.size\n",
    "    order = np.argsort(-np.abs(t_stats))\n",
    "    t_desc = np.abs(t_stats[order])\n",
    "    alpha_r = np.arange(1, M+1) * q / M\n",
    "    crit = t.ppf(1 - alpha_r/2, df=df)\n",
    "    hits = t_desc >= crit\n",
    "    keep = np.zeros(M, bool)\n",
    "    if np.any(hits):\n",
    "        r = np.max(np.where(hits)[0]) + 1\n",
    "        keep[order[:r]] = True\n",
    "    return keep\n",
    "\n",
    "# 3) BH on t-stats (PyTorch) with precomputed critical values\n",
    "def bh_tstat_torch_precomputed(t_stats: torch.Tensor, crit: torch.Tensor) -> torch.BoolTensor:\n",
    "    flat = t_stats.flatten()\n",
    "    M = flat.numel()\n",
    "    device = flat.device\n",
    "\n",
    "    abs_flat = flat.abs()\n",
    "    order = torch.argsort(abs_flat, descending=True)\n",
    "    t_desc = abs_flat[order]\n",
    "\n",
    "    hits = t_desc >= crit\n",
    "    keep_flat = torch.zeros(M, dtype=torch.bool, device=device)\n",
    "    if hits.any():\n",
    "        last = torch.nonzero(hits, as_tuple=False).max()\n",
    "        keep_flat[order[: last.item() + 1 ]] = True\n",
    "\n",
    "    return keep_flat.view(t_stats.shape)\n",
    "\n",
    "# —— Main comparison script —— \n",
    "np.random.seed(0)\n",
    "M, m, df, q = 20000, 30, 29, 0.05\n",
    "\n",
    "# Simulate data & small true shifts\n",
    "data = np.random.randn(M, m)\n",
    "signal_idx = np.random.choice(M, size=int(0.05*M), replace=False)\n",
    "data[signal_idx] += 0.5\n",
    "\n",
    "# Compute t-stats & p-values\n",
    "t_stats = np.empty(M); pvals = np.empty(M)\n",
    "for i in range(M):\n",
    "    t_stats[i], pvals[i] = ttest_1samp(data[i], popmean=0.0)\n",
    "\n",
    "# Precompute critical curve once in NumPy, move to torch\n",
    "alpha_r = np.arange(1, M+1) * (q / M)\n",
    "crit_np  = t.ppf(1 - alpha_r/2, df=df)              # length-M\n",
    "device   = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "crit_torch = torch.tensor(crit_np, device=device, dtype=torch.float32)\n",
    "\n",
    "# Apply BH procedures\n",
    "keep_p    = bh_pvalue(pvals, q=q)\n",
    "keep_t_np = bh_tstat_numpy(t_stats, df=df, q=q)\n",
    "\n",
    "t_torch   = torch.from_numpy(t_stats.astype(np.float32)).to(device)\n",
    "keep_t_t  = bh_tstat_torch_precomputed(t_torch, crit_torch).cpu().numpy()\n",
    "\n",
    "# Compare selections\n",
    "print(\"Discoveries (p-value) :\", keep_p.sum())\n",
    "print(\"Discoveries (NumPy t) :\", keep_t_np.sum())\n",
    "print(\"Discoveries (Torch t) :\", keep_t_t.sum())\n",
    "print(\"NumPy vs Torch equal? :\", np.array_equal(keep_t_np, keep_t_t))\n",
    "print(\"p-value vs Torch equal?:\", np.array_equal(keep_p, keep_t_t))\n",
    "\n",
    "# Ranking Spearman ρ\n",
    "rank_p = rankdata(pvals, method='ordinal')\n",
    "rank_t = rankdata(-np.abs(t_stats), method='ordinal')\n",
    "rho, _ = spearmanr(rank_p, rank_t)\n",
    "print(\"Spearman ρ (p vs |t| ranks):\", rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb6715a-91b2-496f-ad50-b1ea32ebc168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_err: mean=0.024, sd=0.001\n",
      "var_err: mean=0.066, sd=0.004\n",
      "ks_reject: mean=0.001, sd=0.004\n",
      "corr_err: mean=0.040, sd=0.001\n",
      "R_err: mean=0.037, sd=0.001\n",
      "gof_reject: mean=0.000, sd=0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jislam/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.discrete.discrete_model import NegativeBinomial\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def _fit_nb_mle(counts_1d):\n",
    "    \"\"\"\n",
    "    Fit an intercept-only Negative Binomial by MLE.\n",
    "    Returns\n",
    "    -------\n",
    "    mu : float\n",
    "        Estimated mean (exp(intercept)).\n",
    "    size : float\n",
    "        Estimated NB size (r = 1/alpha).\n",
    "    \"\"\"\n",
    "    endog = counts_1d\n",
    "    exog = np.ones((len(endog), 1))\n",
    "    model = NegativeBinomial(endog, exog)\n",
    "    res = model.fit(disp=False, maxiter=100, method=\"bfgs\")\n",
    "    intercept = res.params[0]\n",
    "    mu = np.exp(intercept)\n",
    "    # dispersion alpha is last parameter in statsmodels >=0.13\n",
    "    alpha = res.params_alpha if hasattr(res, 'params_alpha') else res.params[-1]\n",
    "    size = 1.0 / alpha\n",
    "    return mu, size\n",
    "\n",
    "\n",
    "def _counts_to_uniform(counts, mu, size, rng, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Randomized PIT for NB-distributed counts:\n",
    "    maps integer counts to Uniform(eps,1-eps).\n",
    "    \"\"\"\n",
    "    lo = stats.nbinom.cdf(counts - 1, size, size / (size + mu))\n",
    "    hi = stats.nbinom.cdf(counts,     size, size / (size + mu))\n",
    "    u = lo + rng.random(counts.shape) * (hi - lo)\n",
    "    return np.clip(u, eps, 1 - eps)\n",
    "\n",
    "\n",
    "def fit_nb_per_gene(counts_df, progress=True):\n",
    "    \"\"\"\n",
    "    Fit NB to each gene (row) independently.\n",
    "    Returns Series mu and size indexed by gene.\n",
    "    \"\"\"\n",
    "    mus, sizes = [], []\n",
    "    iterator = tqdm(counts_df.iterrows(), total=counts_df.shape[0],\n",
    "                    disable=not progress, desc=\"NB fits\")\n",
    "    for gene, row in iterator:\n",
    "        mu, size = _fit_nb_mle(row.values)\n",
    "        mus.append(mu)\n",
    "        sizes.append(size)\n",
    "    return pd.Series(mus, index=counts_df.index, name=\"mu\"), \\\n",
    "           pd.Series(sizes, index=counts_df.index, name=\"size\")\n",
    "\n",
    "\n",
    "def fit_correlation(counts_df, mu, size, seed=0):\n",
    "    \"\"\"\n",
    "    Estimate latent Gaussian correlation via PIT + Ledoit-Wolf shrinkage.\n",
    "    Returns\n",
    "    -------\n",
    "    R_shrunk : ndarray (G×G)\n",
    "        Shrunk correlation matrix.\n",
    "    lambda_opt : float\n",
    "        Ledoit-Wolf shrinkage intensity.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    G, C = counts_df.shape\n",
    "    U = np.empty((G, C), float)\n",
    "    for j, g in enumerate(counts_df.index):\n",
    "        U[j] = _counts_to_uniform(counts_df.loc[g].values, mu[g], size[g], rng)\n",
    "\n",
    "    Z = stats.norm.ppf(U)\n",
    "\n",
    "    # Ledoit-Wolf on cells×genes\n",
    "    lw = LedoitWolf().fit(Z.T)\n",
    "    Sigma = lw.covariance_\n",
    "    d = np.sqrt(np.diag(Sigma))\n",
    "    R_shrunk = Sigma / np.outer(d, d)\n",
    "\n",
    "    return R_shrunk, lw.shrinkage_\n",
    "\n",
    "\n",
    "class NBCopulaModel:\n",
    "    \"\"\"\n",
    "    NB-Gaussian copula model: stores mu, size, and latent correlation R.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu, size, R):\n",
    "        self.mu, self.size, self.R = mu, size, R\n",
    "        self._chol = np.linalg.cholesky(R)\n",
    "\n",
    "    def simulate(self, n_cells, seed=0):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        G = len(self.mu)\n",
    "        Z = self._chol @ rng.standard_normal((G, n_cells))\n",
    "        U = stats.norm.cdf(Z)\n",
    "        counts = np.empty_like(U, dtype=int)\n",
    "        for j, g in enumerate(self.mu.index):\n",
    "            counts[j] = stats.nbinom.ppf(\n",
    "                U[j], self.size[g], self.size[g] / (self.size[g] + self.mu[g])\n",
    "            )\n",
    "        return pd.DataFrame(counts, index=self.mu.index,\n",
    "                            columns=[f\"cell_{i}\" for i in range(n_cells)])\n",
    "\n",
    "        mu_hat, size_hat = fit_nb_per_gene(df, progress=False)\n",
    "        R_hat, lam = fit_correlation(df, mu_hat, size_hat, seed=seed+1)\n",
    "        model = NBCopulaModel(mu_hat, size_hat, R_hat)\n",
    "        sim = model.simulate(C, seed=seed+2)\n",
    "def test_nb_copula(G=50, C=1000, n_reps=50, seed=0):\n",
    "    \"\"\"\n",
    "    Empirical assessment of NB-copula fitting & simulation.\n",
    "    Adds marginal NB goodness-of-fit checks.\n",
    "\n",
    "    Returns dict of (mean, std) for each metric.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # true NB params & correlation\n",
    "    true_mu   = rng.uniform(1, 6,  G)\n",
    "    true_size = rng.uniform(0.5, 3, G)\n",
    "    eig = rng.dirichlet(np.ones(G)) * G\n",
    "    R_true = stats.random_correlation(eig, seed=seed).rvs()\n",
    "\n",
    "    # containers\n",
    "    metrics = {k: [] for k in [\n",
    "        'mean_err','var_err','ks_reject','corr_err','R_err','gof_reject'\n",
    "    ]}\n",
    "\n",
    "    for rep in range(n_reps):\n",
    "        # simulate ground-truth counts\n",
    "        L = np.linalg.cholesky(R_true)\n",
    "        Zg = L @ rng.standard_normal((G, C))\n",
    "        Ug = stats.norm.cdf(Zg)\n",
    "        counts = np.array([stats.nbinom.ppf(Ug[j], true_size[j],\n",
    "                          true_size[j]/(true_size[j]+true_mu[j]))\n",
    "                          for j in range(G)])\n",
    "        df = pd.DataFrame(counts, index=[f\"g{j}\" for j in range(G)])\n",
    "\n",
    "        # fit & simulate\n",
    "        mu_hat, size_hat = fit_nb_per_gene(df, progress=False)\n",
    "        R_hat, lam = fit_correlation(df, mu_hat, size_hat, seed=seed+1)\n",
    "        model = NBCopulaModel(mu_hat, size_hat, R_hat)\n",
    "        sim = model.simulate(C, seed=seed+2)\n",
    "\n",
    "        # metrics\n",
    "        metrics['mean_err'].append(np.mean(np.abs(sim.mean(1)-df.mean(1))/df.mean(1)))\n",
    "        metrics['var_err'].append(np.mean(np.abs(sim.var(1)-df.var(1))/df.var(1)))\n",
    "        ks_p = [stats.ks_2samp(sim.loc[g], df.loc[g]).pvalue for g in df.index]\n",
    "        metrics['ks_reject'].append(np.mean(np.array(ks_p) < 0.05))\n",
    "        metrics['corr_err'].append(\n",
    "            np.linalg.norm(np.corrcoef(sim)-np.corrcoef(df), ord='fro')/G\n",
    "        )\n",
    "        metrics['R_err'].append(\n",
    "            np.linalg.norm(R_hat-R_true, ord='fro')/G\n",
    "        )\n",
    "        # marginal NB goodness-of-fit via one-sample KS on randomized PIT\n",
    "        gof = []\n",
    "        for j, g in enumerate(df.index):\n",
    "            u = _counts_to_uniform(df.loc[g].values, mu_hat[g], size_hat[g], rng)\n",
    "            # test Uniform(0,1)\n",
    "            _, pval = stats.kstest(u, 'uniform', args=(0,1))\n",
    "            gof.append(pval)\n",
    "        metrics['gof_reject'].append(np.mean(np.array(gof) < 0.05))\n",
    "\n",
    "    # summarize\n",
    "    return {k: (np.mean(v), np.std(v)) for k, v in metrics.items()}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    res = test_nb_copula()\n",
    "    for name, (m, s) in res.items():\n",
    "        print(f\"{name}: mean={m:.3f}, sd={s:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
